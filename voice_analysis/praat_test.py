# -*- coding: utf-8 -*-
"""Praat_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M1gSHUaeNbZHrAocR_6ZQvakQ0sc-tzt
"""

!pip install praat-parselmouth

# 필요한 라이브러리 설치
!pip install pydub
!apt-get install ffmpeg  # Colab에서 FFmpeg 설치

from pydub import AudioSegment

# M4A 파일을 WAV로 변환
audio = AudioSegment.from_file("test5.m4a", format="m4a")
audio.export("test5.wav", format="wav")

!pip install noisereduce

import parselmouth
import noisereduce as nr
import numpy as np
import scipy.io.wavfile as wav

import parselmouth
import numpy as np
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt

# 1. WAV 파일 불러오기
file_path = "test4.wav"  # 분석할 음성 파일 경로
sampling_rate, audio_data = wav.read(file_path)  # scipy로 파일 로드

# 2. 피치 분석 (parselmouth 사용)
sound = parselmouth.Sound(file_path)  # parselmouth로 음성 로드
pitch = sound.to_pitch()

# 3. 피치 정보 추출
print("시작 시간: ", pitch.start_time)
print("끝 시간: ", pitch.end_time)

pitch_values = pitch.selected_array['frequency']
valid_pitch_values = pitch_values[pitch_values > 0]  # 유효한 피치 값만 사용

# 피치의 평균 계산
average_pitch = np.mean(valid_pitch_values) if len(valid_pitch_values) > 0 else 0
print("평균 피치: ", average_pitch)

# 4. 파형과 피치 그래프 그리기
def plot_waveform_and_pitch(audio_data, sampling_rate, pitch):
    # 시간 축 생성
    time_axis = np.linspace(0, len(audio_data) / sampling_rate, num=len(audio_data))

    # 그래프 설정
    plt.figure(figsize=(10, 6))

    # 1. 파형 그리기
    plt.subplot(2, 1, 1)
    plt.plot(time_axis, audio_data, color='tab:blue')
    plt.title("Waveform")
    plt.xlabel("Time [s]")
    plt.ylabel("Amplitude")
    plt.grid(True)

    # 2. 피치 그리기
    plt.subplot(2, 1, 2)
    plt.plot(pitch.xs(), pitch.selected_array['frequency'], 'o', markersize=5, color='tab:red')
    plt.title("Pitch")
    plt.xlabel("Time [s]")
    plt.ylabel("Frequency [Hz]")
    plt.grid(True)

    # 그래프 보여주기
    plt.tight_layout()
    plt.show()

# 5. 함수 호출하여 그래프 표시
plot_waveform_and_pitch(audio_data, sampling_rate, pitch)

#노이즈제거가 포함된 버전. 끊기는 경우가 있음
import parselmouth
import noisereduce as nr
import scipy.io.wavfile as wav
import numpy as np
import matplotlib.pyplot as plt

# 1. WAV 파일 로드
file_path = "test1.wav"

# WAV 파일을 로드해 샘플링 레이트와 데이터를 가져옵니다.
sampling_rate, data = wav.read(file_path)

# 스테레오일 경우, 단일 채널로 변환
if len(data.shape) > 1:
    data = data.mean(axis=1).astype(np.int16)

# 2. 노이즈 제거
# 첫 5000 샘플을 노이즈 클립으로 사용
noise_clip = data[:5000]

# 노이즈 감소 적용 (전체 음성을 유지하며 노이즈만 줄임)
reduced_noise = nr.reduce_noise(y=data, sr=sampling_rate, y_noise=noise_clip, prop_decrease=0.9)

# 3. parselmouth로 음성 분석
snd = parselmouth.Sound(reduced_noise, sampling_rate)

# 4. 피치 분석
pitch = snd.to_pitch()
pitch_values = pitch.selected_array["frequency"]

# 인간 목소리 범위 (30 Hz ~ 255 Hz)
human_voice_range = (30, 255)

# 5. 피치 값 필터링
# 사람이 말하는 부분의 피치 값만 남깁니다.
pitch_values_human = pitch_values[(pitch_values >= human_voice_range[0]) & (pitch_values <= human_voice_range[1])]

# 피치의 평균, 최소, 최대 계산
if pitch_values_human.size > 0:
    pitch_mean = np.mean(pitch_values_human)
    pitch_min = np.min(pitch_values_human)
    pitch_max = np.max(pitch_values_human)

    print(f"Pitch mean: {pitch_mean:.2f} Hz, Pitch min: {pitch_min:.2f} Hz, Pitch max: {pitch_max:.2f} Hz")
else:
    print("No pitch values found in the human voice range.")

# 6. 노이즈 제거된 음성 저장
output_file = "saturi_reduced.wav"
wav.write(output_file, sampling_rate, reduced_noise.astype(np.int16))

print(f"{output_file} 파일이 생성되었습니다.")

# 7. 파형 및 피치 그래프 그리기
plt.figure()

# 파형 그리기
plt.subplot(2, 1, 1)
plt.plot(np.arange(len(reduced_noise)) / sampling_rate, reduced_noise)
plt.xlim([0, len(reduced_noise) / sampling_rate])
plt.ylabel("Amplitude")
plt.title("Waveform (Reduced Noise)")

# 피치 그리기 (인간 음역대만 표시)
plt.subplot(2, 1, 2)
plt.plot(pitch.xs(), pitch.selected_array["frequency"], "o", markersize=5, label="Pitch")
plt.xlim([0, len(reduced_noise) / sampling_rate])
plt.ylim(60, 300)  # 피치 범위 설정 (60 Hz ~ 300 Hz)
plt.ylabel("Frequency (Hz)")
plt.title("Pitch (Human Voice Range)")
plt.show()

#인간의 음역대만 따온 버전. 인간의 음역대가 끝나고 여유 시간을 둬서 완성도 있게 필터함.
import parselmouth
import scipy.io.wavfile as wav
import numpy as np
import matplotlib.pyplot as plt

# 1. WAV 파일 로드
file_path = "test5.wav"

# WAV 파일 읽기 (샘플링 레이트와 데이터 반환)
sampling_rate, data = wav.read(file_path)

# 스테레오일 경우 단일 채널로 변환
if len(data.shape) > 1:
    data = data.mean(axis=1).astype(np.int16)

# 2. parselmouth로 음성 분석
snd = parselmouth.Sound(data, sampling_rate)

# 피치 분석 (사람의 음역대)
pitch = snd.to_pitch()
human_voice_range = (30, 255)  # 사람 목소리 범위

# 피치 값과 해당 시간 단계 가져오기
pitch_values = pitch.selected_array["frequency"]
time_steps = pitch.xs()

# 3. 끊김 방지용 히스테리시스 필터 적용
filtered_data = np.zeros_like(data, dtype=np.float32)  # 원본과 동일한 크기의 배열 생성
prev_in_range = False  # 이전 샘플이 인간 음역대에 있었는지 추적

# 히스테리시스: 피치가 범위를 벗어났더라도 일정 구간을 유지 (50ms)
extend_ms = 50  # 유지할 길이 (밀리초)
silence_after_ms = 200  # 말이 끝난 후 유지할 여유 시간 (밀리초)
extend_samples = int(sampling_rate * extend_ms / 1000)  # 샘플 수로 변환
silence_samples = int(sampling_rate * silence_after_ms / 1000)  # 여유 시간 샘플 수

for i, t in enumerate(time_steps):
    index = int(t * sampling_rate)  # 시간 단계를 샘플 인덱스로 변환

    # 현재 피치가 인간 음역대에 해당하는지 확인
    in_range = human_voice_range[0] <= pitch_values[i] <= human_voice_range[1]

    if in_range or prev_in_range:
        # 앞뒤로 extend_ms만큼 구간을 유지
        start = max(0, index - extend_samples)
        end = min(len(data), index + extend_samples + silence_samples)
        filtered_data[start:end] = data[start:end]

    # 현재 상태를 다음 반복에 전달
    prev_in_range = in_range

# 4. 결과를 WAV 파일로 저장
output_file = "human_voice_only_hysteresis.wav"
wav.write(output_file, sampling_rate, filtered_data.astype(np.int16))

print(f"{output_file} 파일이 생성되었습니다.")

# 5. 파형 및 피치 그래프 그리기
plt.figure()

# 파형 그리기
plt.subplot(2, 1, 1)
plt.plot(np.arange(len(filtered_data)) / sampling_rate, filtered_data)
plt.xlim([0, len(filtered_data) / sampling_rate])
plt.ylabel("Amplitude")
plt.title("Waveform (Human Voice Only with Hysteresis)")

# 피치 그리기 (인간 음역대만 표시)
plt.subplot(2, 1, 2)
plt.plot(time_steps, pitch_values, "o", markersize=5, label="Pitch")
plt.xlim([0, len(data) / sampling_rate])
plt.ylim(30, 255)  # 피치 범위 설정
plt.ylabel("Frequency (Hz)")
plt.title("Pitch (Human Voice Range)")
plt.show()

import parselmouth
import noisereduce as nr
import scipy.io.wavfile as wav
import numpy as np
import matplotlib.pyplot as plt

# 1. WAV 파일 로드
file_path = "test_ji.wav"

# WAV 파일을 로드해 샘플링 레이트와 데이터를 가져옵니다.
sampling_rate, data = wav.read(file_path)

# 스테레오일 경우, 단일 채널로 변환
if len(data.shape) > 1:
    data = data.mean(axis=1).astype(np.int16)

# 2. 노이즈 제거
# 첫 5000 샘플을 노이즈 클립으로 사용
noise_clip = data[:5000]

# 노이즈 감소 적용 (전체 음성을 유지하며 노이즈만 줄임)
reduced_noise = nr.reduce_noise(y=data, sr=sampling_rate, y_noise=noise_clip, prop_decrease=0.9)

# 3. parselmouth로 음성 분석
snd = parselmouth.Sound(reduced_noise, sampling_rate)

# 4. 피치 분석
pitch = snd.to_pitch()
pitch_values = pitch.selected_array["frequency"]

# 피치의 평균, 최소, 최대 계산
if pitch_values.size > 0:
    pitch_mean = np.mean(pitch_values)
    pitch_min = np.min(pitch_values)
    pitch_max = np.max(pitch_values)

    print(f"Pitch mean: {pitch_mean:.2f} Hz, Pitch min: {pitch_min:.2f} Hz, Pitch max: {pitch_max:.2f} Hz")
else:
    print("No pitch values found.")

# 5. 노이즈 제거된 음성 저장
output_file = "saturi_reduced.wav"
wav.write(output_file, sampling_rate, reduced_noise.astype(np.int16))

print(f"{output_file} 파일이 생성되었습니다.")

# 6. 파형 및 피치 그래프 그리기
plt.figure()

# 파형 그리기
plt.subplot(2, 1, 1)
plt.plot(np.arange(len(reduced_noise)) / sampling_rate, reduced_noise)
plt.xlim([0, len(reduced_noise) / sampling_rate])
plt.ylabel("Amplitude")
plt.title("Waveform (Reduced Noise)")

# 피치 그리기
plt.subplot(2, 1, 2)
plt.plot(pitch.xs(), pitch.selected_array["frequency"], "o", markersize=5, label="Pitch")
plt.xlim([0, len(reduced_noise) / sampling_rate])
plt.ylim(0, 300)  # 피치 범위 설정
plt.ylabel("Frequency (Hz)")
plt.title("Pitch")
plt.show()